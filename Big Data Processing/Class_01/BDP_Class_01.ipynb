{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ef1024f-36cc-4fae-856f-23ac2dd50422",
   "metadata": {},
   "source": [
    "# Занятие №1. Параллельная обработка данных на чистом Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c9fed2-fb5b-4458-8ed6-929e88638927",
   "metadata": {},
   "source": [
    "На занятии с помощью Python мы воспроизвели паттерны, которые Apache Spark использует «под капотом». Программа, которая получилась в конце, читает большой файл с датасетом, фильтрует нужные события, группирует их в пакеты, после чего ообрабатывает параллельно в нескольких процессах. \n",
    "\n",
    "**Такой подход позволяет решить две проблемы:**\n",
    "- файл с событиями может весить десятки гигабайт, если загрузить его целиком в список Python, программа упадёт с ошибкой `MemoryError` или начнёт использовать `swap`, что сильно замедлит работу;\n",
    "- интепретатор Python выполняет байткод только в одном потоке одновременно, даже если в компьютере, например, восемь ядер, обычная однопоточная программа нагрузит только одно из них, а остальные семь будут простаивать.\n",
    "\n",
    "Финальный вариант программа состоит из несколько логических блоков, по которым мы разделим наши действия.\n",
    "\n",
    "**Всего таких блоков восемь:**\n",
    "1. **Прописываем импорты и настраиваем окружение.** Прежде чем писать логику обработки, нужно настроить окружение. Программа использует несколько модулей стандартной библиотеки:\n",
    "\n",
    "    - **functools** — содержит утилиты, которые позволяют работать с функциями. Из этого модуля нам понадобится декоратор `wraps`, который сохраняет метаданные функции, которую мы будем оборачивать;\n",
    "    - **json** — парсит JSON-строки в словари Python;\n",
    "    - **logging** — выводит сообщения с информацией о том, как выполняется программа, логирование поможет нам понять, что делает конкретный процесс;\n",
    "    - **time** — измеряет время, за которое выполняются функции;\n",
    "    - **collections.abc** — содержит абстрактные типы `Iterable` и `Iterator` для аннотаций, которые мы будем использовать;\n",
    "    - **concurrent.futures** — содержит высокоуровневый интерфейс, который позволяет запускать задачи параллельно в нескольких процессах или потоках;\n",
    "    - **pathlib** — предоставляет пути к файлам как к объектам, а не строкам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28492de-2a55-4930-b0c3-e6d3948c8498",
   "metadata": {},
   "source": [
    "Константа `WORKDIR` хранит путь к директории, где лежит скрипт. От неё мы будем строить относительные пути к данным.\n",
    "\n",
    "Сам логгер мы настраиваем так, чтобы каждое сообщение содержало имя процесса. Когда мы запустим несколько процессов параллельно, то сразу увидим, какой из них пишет в лог."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f549a972-a899-4af9-9604-e319de28317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фрагмент программы №1\n",
    "\n",
    "import functools\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "from collections.abc import Iterable, Iterator\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "\n",
    "WORKDIR = Path(__file__).parent\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(processName)s %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b9d057-7de5-45e9-9ad2-39f7a76b6636",
   "metadata": {},
   "source": [
    "2. **Используем декоратор `slowlog`**\n",
    "    \n",
    "    **Декоратор** — это функция, которая принимает другую функцию и возвращает её модифицированную версию. Декораторы позволяют добавить поведение к функции, но при этом не менять её код.\n",
    "\n",
    "    Декоратор `slowlog` измеряет, сколько времени выполняется функция, и пишет результат в лог. Параметр `threshold` задаёт порог в секундах. Если функция выполняется дольше, чем этот порог, то декоратор помечает её в логе, что она слишком медленная.\n",
    "\n",
    "    Кроме того, здесь используется **фабрика декораторов** — функция, которая возвращает декоратор. Такая конструкция нужна, чтобы передать параметр `threshold`. \n",
    "\n",
    "    **Давайте разберём её структуру:**\n",
    "    1. **`slowlog(threshold)`** — это внешняя функция, которая принимает параметр `threshold` и возвращает декоратор `set_timer`.\n",
    "    2. **`@functools.wraps(func)`** — это декоратор, который копирует в обёртку метаданные оригинальной функции. Например, имя и документацию. Без него `wrapper.__name__` вернул бы просто `\"wrapper\"` вместо настоящего имени функции.\n",
    "    3. **`set_timer(func)`** — это сам декоратор, который принимает функцию и возвращает обёртку `wrapper`.\n",
    "    4. **`wrapper(*args, **kwargs)`** — это обёртка, которая вызывает оригинальную функцию и логирует результат.\n",
    "    5. **`time.perf_counter()`** — это функция, возвращает время с максимальной точностью. Она лучше подходит, чтобы измерять короткие интервалы, чем `time.time()`.\n",
    "    6. **`try/finally`** — это блок, который гарантирует, что время запишется в лог даже если функция выбросит исключение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc055a1-ecaa-4411-b863-b68c997d1f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Фрагмент программы №2\n",
    "\n",
    "def slowlog(threshold: float = 2.5):\n",
    "    def set_timer(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            start = time.perf_counter()\n",
    "            try:\n",
    "                result = func(*args, **kwargs)\n",
    "            finally:\n",
    "                delta = time.perf_counter() - start\n",
    "                if delta > threshold:\n",
    "                    logger.info(\"Finished %s in %.3f seconds (too slow)\", func.__name__, delta)\n",
    "                else:\n",
    "                    logger.info(\"Finished %s in %.3f seconds\", func.__name__, delta)\n",
    "            return result\n",
    "        return wrapper\n",
    "    return set_timer\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1004c100-1e89-42cc-b430-c7b609b27b79",
   "metadata": {},
   "source": [
    "3. **Используем генератор `read_events`.**\n",
    "\n",
    "    **Генератор** — это функция, которая использует ключевое слово `yield` вместо `return`. Генератор не выполняет всю работу сразу, он возвращает объект-итератор, который выдаёт по одному значению при каждом обращении.\n",
    "\n",
    "    Функция `read_events` читает файл в формате **JSONL, или JSON Lines,** — это формат, в котором каждая строка файла является отдельным JSON-объектом. Такой формат удобно использовать для потоковой обработки, так как нам не нужно парсить весь файл целиком, чтобы получить первую запись.\n",
    "\n",
    "    Генератор открывает файл и проходит по нему построчно. Каждую строку он парсит в словарь и отдаёт через `yield`. Важно отметить, что пока внешний код не запрос следующее значение, генератор стоит на паузе и не читает следующую строку. Такой подход называется **ленивым вычислением**. Он позволяет сэкономить оперативную память, так как в каждый момент памяти находится только одна строка файла, а не весь файл целиком.\n",
    "\n",
    "    Аннотация `Iterator[dict]` говорит нам, что функция возвращает итератор, который выдаёт словари."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be58b18-aabd-492b-ae80-25f501ba05e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фрагмент программы №3\n",
    "\n",
    "def read_events(path: Path) -> Iterator[dict]:\n",
    "    with open(path, \"r\", encodiing=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            yield json.loads(line)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9eb0c6-938d-404c-85d0-6a9454938412",
   "metadata": {},
   "source": [
    "4. **Используем генератор `filter_events`.**\n",
    "\n",
    "    Функция `filter_events` принимает итератор событий и возвращает новый итератор, который пропускает только события с нужным типом. Этот генератор тоже ленивый, так как он не создаёт список отфильтрованных событий в памяти. Вместо этого он берёт события из входного итератора по одному, проверяет условие и отдаёт подходящие дальше.\n",
    "\n",
    "    Когда мы соединяем `read_events` и `filter_events` в цепочку, то получаем **пайплайн** — это последовательность преобразований, где каждое звено обрабатывает данные и передаёт следующие. Важно отметить, что при этом ни одно звено не хранит данные целиком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd251ebf-22a3-4588-acfa-934737da80ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фрагмент программы №4\n",
    "\n",
    "def filter_events(events: Iterator[dict], wanted_event_type: str) -> Iterator[dict]:\n",
    "    for event in events:\n",
    "        if event[\"event_type\"] == wanted_event_type:\n",
    "            yield event\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d8e5ed-6061-472f-94ef-57bb14f621dd",
   "metadata": {},
   "source": [
    "5. **Группируем потоки в пакеты.**\n",
    "\n",
    "    **Батч** — это пакет элементов фиксированного размера.\n",
    "\n",
    "    Когда программа передаёт данные в другой процесс, она сначала сериализует их, или превращает в байты, после чего отправляет, а процесс-получатель десереализует эти данные обратно. Эти операции занимают время. Если отправлять события по одному, то расходы на передачу данные перекроют время, которые мы получили благодаря параллельной обработки. Крупные пакеты выгоднее передавать, так как мы передаём один большой вместо тысяч маленьких.\n",
    "\n",
    "    Функция `batcher` принимает итератор и размер батча. Она складывает элементы в список. Как только список достигает нужного размера, `batcher` отдаёт его через `yield` и начинает собирать следующий. После того, как цикл завершиться, в конце файла элементов может быть меньше, чем размер батча. Для этого мы используем условие `if batch`, чтобы проверить, так ли это, и отдать остаток элементов последним неполным пакетом.\n",
    "\n",
    "    Аннтоация `Iterable[list[dict]]` говорит нам, что функция возвращает итерируемый объект, который выдаёт списки словарей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56843941-9460-42ef-ac28-8468a665a128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фрагмент программы №5\n",
    "\n",
    "def batcher(iterable: Iterable[dict], batch_size: шт) -> Iterable[list[dict]]:\n",
    "    batch = []\n",
    "    for item in iterable:\n",
    "        batch.append(item)\n",
    "        if len(batch) == batch_size:\n",
    "            yield batch\n",
    "            batch = []\n",
    "        if batch:\n",
    "            yield batch\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eabc3a-a014-4d37-be86-30a05de4b931",
   "metadata": {},
   "source": [
    "6. **Обрабатываем батч и имитируем CPU-bound операцию.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710ffe88-4374-43d9-bf90-636e84ea0e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
